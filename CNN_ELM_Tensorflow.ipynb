{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-ELM_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX46RYryMlvi",
        "outputId": "d434a477-7650-4149-bbdc-c34d7877e345"
      },
      "source": [
        "#Install elm package temporarily\n",
        "!pip install hpelm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hpelm in /usr/local/lib/python3.6/dist-packages (1.0.10)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.6/dist-packages (from hpelm) (0.16)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from hpelm) (3.4.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hpelm) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.12 in /usr/local/lib/python3.6/dist-packages (from hpelm) (1.4.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from hpelm) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hpelm) (1.19.5)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->hpelm) (2.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vVbL2ZaO2tu",
        "outputId": "6d99f6ee-c0fa-454a-c5b9-c7a6ed074d8e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import hpelm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "u4fZgGKfO2tw",
        "outputId": "d5b3ac68-6636-44c9-e702-06756554ed60"
      },
      "source": [
        "#Load data frame using pandas\n",
        "df = pd.read_csv('/content/drive/My Drive/1_gecco2019_water_quality.csv', index_col = 0)\n",
        "df\n",
        "#Colab Notebooks/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Tp</th>\n",
              "      <th>pH</th>\n",
              "      <th>Cond</th>\n",
              "      <th>Turb</th>\n",
              "      <th>SAC</th>\n",
              "      <th>PFM</th>\n",
              "      <th>Event</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-07-01 00:00:00</td>\n",
              "      <td>6.94</td>\n",
              "      <td>8.60774</td>\n",
              "      <td>0.020954</td>\n",
              "      <td>0.125931</td>\n",
              "      <td>3.58683</td>\n",
              "      <td>43.7559</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-07-01 00:01:00</td>\n",
              "      <td>6.93</td>\n",
              "      <td>8.60589</td>\n",
              "      <td>0.020965</td>\n",
              "      <td>0.127219</td>\n",
              "      <td>3.59025</td>\n",
              "      <td>43.4366</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-07-01 00:02:00</td>\n",
              "      <td>6.94</td>\n",
              "      <td>8.60220</td>\n",
              "      <td>0.020968</td>\n",
              "      <td>0.126482</td>\n",
              "      <td>3.58318</td>\n",
              "      <td>43.5994</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-07-01 00:03:00</td>\n",
              "      <td>6.94</td>\n",
              "      <td>8.60220</td>\n",
              "      <td>0.020972</td>\n",
              "      <td>0.126184</td>\n",
              "      <td>3.58769</td>\n",
              "      <td>43.3704</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017-07-01 00:04:00</td>\n",
              "      <td>6.94</td>\n",
              "      <td>8.60405</td>\n",
              "      <td>0.020974</td>\n",
              "      <td>0.127908</td>\n",
              "      <td>3.58287</td>\n",
              "      <td>43.1656</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132476</th>\n",
              "      <td>2017-09-30 23:55:00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8.56593</td>\n",
              "      <td>0.020724</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>4.53577</td>\n",
              "      <td>56.4686</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132477</th>\n",
              "      <td>2017-09-30 23:56:00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8.56593</td>\n",
              "      <td>0.020727</td>\n",
              "      <td>0.126575</td>\n",
              "      <td>4.53008</td>\n",
              "      <td>56.3567</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132478</th>\n",
              "      <td>2017-09-30 23:57:00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8.56593</td>\n",
              "      <td>0.020723</td>\n",
              "      <td>0.126512</td>\n",
              "      <td>4.53512</td>\n",
              "      <td>55.0477</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132479</th>\n",
              "      <td>2017-09-30 23:58:00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8.56228</td>\n",
              "      <td>0.020720</td>\n",
              "      <td>0.126477</td>\n",
              "      <td>4.54084</td>\n",
              "      <td>55.4052</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132480</th>\n",
              "      <td>2017-09-30 23:59:00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8.56410</td>\n",
              "      <td>0.020723</td>\n",
              "      <td>0.126566</td>\n",
              "      <td>4.53445</td>\n",
              "      <td>54.9886</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132480 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Time     Tp       pH  ...      SAC      PFM  Event\n",
              "1       2017-07-01 00:00:00   6.94  8.60774  ...  3.58683  43.7559  False\n",
              "2       2017-07-01 00:01:00   6.93  8.60589  ...  3.59025  43.4366  False\n",
              "3       2017-07-01 00:02:00   6.94  8.60220  ...  3.58318  43.5994  False\n",
              "4       2017-07-01 00:03:00   6.94  8.60220  ...  3.58769  43.3704  False\n",
              "5       2017-07-01 00:04:00   6.94  8.60405  ...  3.58287  43.1656  False\n",
              "...                     ...    ...      ...  ...      ...      ...    ...\n",
              "132476  2017-09-30 23:55:00  10.30  8.56593  ...  4.53577  56.4686  False\n",
              "132477  2017-09-30 23:56:00  10.30  8.56593  ...  4.53008  56.3567  False\n",
              "132478  2017-09-30 23:57:00  10.30  8.56593  ...  4.53512  55.0477  False\n",
              "132479  2017-09-30 23:58:00  10.30  8.56228  ...  4.54084  55.4052  False\n",
              "132480  2017-09-30 23:59:00  10.30  8.56410  ...  4.53445  54.9886  False\n",
              "\n",
              "[132480 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPCg41yO2tx"
      },
      "source": [
        "#Map True and False to values 0 and 1 respectively\n",
        "\n",
        "#0 represents Anomaly\n",
        "#1 represents Normalcy\n",
        "\n",
        "df['Event'] = df['Event'].astype('category')\n",
        "encode_map ={\n",
        "    False : 1,\n",
        "    True : 0 }\n",
        "\n",
        "df['Event'].replace(encode_map, inplace=True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qofcf7C0O2ty",
        "outputId": "63c04d85-cbbf-4f50-c377-982307ed982c"
      },
      "source": [
        "#Count of values of 0 and 1\n",
        "\n",
        "df['Event'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    132268\n",
              "0       212\n",
              "Name: Event, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pVhyFLuis2n"
      },
      "source": [
        "#Wherever some of the fields are not filled with data,fill those fields with the mean value\n",
        "\n",
        "df['pH'].fillna((df['pH'].mean()), inplace=True)\n",
        "df['Tp'].fillna((df['Tp'].mean()), inplace=True)\n",
        "df['Cond'].fillna((df['Cond'].mean()), inplace=True)\n",
        "df['Turb'].fillna((df['Turb'].mean()), inplace=True)\n",
        "df['SAC'].fillna((df['SAC'].mean()), inplace=True)\n",
        "df['PFM'].fillna((df['PFM'].mean()), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4m2r-r0pSD6",
        "outputId": "8b7374d0-50e6-4665-d0eb-6d5ddcb4fbba"
      },
      "source": [
        "#Data Type conversion\n",
        "\n",
        "df['Time'] = pd.to_datetime(df['Time']).astype(np.int64)\n",
        "df['Tp'] = df['Tp'].astype('float32')\n",
        "df['pH'] = df['pH'].astype('float32')\n",
        "df['Cond'] = df['Cond'].astype('float32')\n",
        "df['Turb'] = df['Turb'].astype('float32')\n",
        "df['SAC'] = df['SAC'].astype('float32')\n",
        "df['PFM'] = df['PFM'].astype('float32')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 132480 entries, 1 to 132480\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    132480 non-null  int64  \n",
            " 1   Tp      132480 non-null  float32\n",
            " 2   pH      132480 non-null  float32\n",
            " 3   Cond    132480 non-null  float32\n",
            " 4   Turb    132480 non-null  float32\n",
            " 5   SAC     132480 non-null  float32\n",
            " 6   PFM     132480 non-null  float32\n",
            " 7   Event   132480 non-null  int64  \n",
            "dtypes: float32(6), int64(2)\n",
            "memory usage: 6.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apw_3JDWO2tz"
      },
      "source": [
        "#Define Input Columns(X) and Output Columns(y) \n",
        "\n",
        "X = df.iloc[:, 1:7]\n",
        "y = df.iloc[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dDviYPuCES2"
      },
      "source": [
        "#Normalise the values\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler() \n",
        "X = scaler.fit_transform(X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jehldK-qO2t0"
      },
      "source": [
        "#Split Train and Test Data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoQCcK2D78T-",
        "outputId": "96c02239-5da0-4912-9026-678151060b12"
      },
      "source": [
        "#Over Sample the Data using SMOTE\n",
        "\n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state=42)\n",
        "x_train, y_train = sm.fit_resample(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aR3NgreEsL3",
        "outputId": "6a36aeb9-774e-4dfc-e364-5067a32ad168"
      },
      "source": [
        "#Encode output\n",
        "\n",
        "y_train=tf.keras.utils.to_categorical(y_train)\n",
        "y_test=tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "#Reshape Train Data\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1], 1)\n",
        "x_test = np.asarray(x_test).reshape(x_test.shape[0],x_test.shape[1], 1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(211610, 6, 1)\n",
            "(211610, 2)\n",
            "(26496, 6, 1)\n",
            "(26496, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOoiwXOrO2t2"
      },
      "source": [
        "verbose, epochs, batch_size = 0, 100, 64\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[0], x_train.shape[1], y_train.shape[1]\n",
        "\n",
        "#Define CNN Model\n",
        "\n",
        "def generate_cnn():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n_outputs, activation='softmax'))\n",
        "  opt = tf.keras.optimizers.SGD(lr=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
        "  print(model.summary())\n",
        "  model.fit(x_train, y_train, epochs=epochs,validation_data=(x_test,y_test), batch_size=batch_size, verbose=1)      \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbZGcxNHVSLU"
      },
      "source": [
        "#Define Hidden Layer\r\n",
        "#The Hidden Layer is the layer between CNN and ELM\r\n",
        "\r\n",
        "def hidden_layer_generate(cnn_model):\r\n",
        "    layer_name = 'flatten'\r\n",
        "    hidden_layer_model = tf.keras.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(layer_name).output)\r\n",
        "    hidden_result = hidden_layer_model.predict(x_train)\r\n",
        "    return hidden_layer_model, hidden_result\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2mOk0_xNcDt"
      },
      "source": [
        "#Define ELM model\r\n",
        "#ELM receives input from the hidden layer and produces the final output\r\n",
        "def elm_model_generate(data_train, target_train):\r\n",
        "\r\n",
        "    elm_model = hpelm.elm.ELM(data_train.shape[1], 2)\r\n",
        "    elm_model.add_neurons(1000, func='sigm')\r\n",
        "    elm_model.train(data_train, y_train, 'c')\r\n",
        "\r\n",
        "    return elm_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjv93txN6W1"
      },
      "source": [
        "#The result of CNN is fed as input to the ELM\r\n",
        "#ELM produces the final output\r\n",
        "#Based on the CNN-ELM's predictions and the expected outputs, the metrics are evaluated\r\n",
        "def cnn_elm_evaluation(cnn_part, elm_part, data_test, target_test):\r\n",
        "\r\n",
        "    cnn_result = cnn_part.predict(x_test)\r\n",
        "    elm_result = elm_part.predict(cnn_result)\r\n",
        "    con_mat=metrics.confusion_matrix(y_test.argmax(axis=1), elm_result.argmax(axis=1)) \r\n",
        "    print()\r\n",
        "    print()\r\n",
        "    print()    \r\n",
        "    print(\"\\t\\t\\t     CONFUSION MATRIX\")\r\n",
        "    print(\"\\t\\t\\t+------------------------+\")\r\n",
        "    print(\"\\t\\t\\t|\\tTP  |\\tFP\\t |\")\r\n",
        "    print(\"\\t\\t\\t+------------------------+\")\r\n",
        "    print(\"\\t\\t\\t|\\t\",con_mat[0][0],\"|\\t\",con_mat[0][1],\"\\t |\")\r\n",
        "    print(\"\\t\\t\\t+------------------------+\")\r\n",
        "    print(\"\\t\\t\\t|\\t\",con_mat[1][0],\"|\\t\",con_mat[1][1],\"\\t |\")\r\n",
        "    print(\"\\t\\t\\t+------------------------+\")\r\n",
        "    print(\"\\t\\t\\t|\\tFN  |\\tTN\\t |\")\r\n",
        "    print(\"\\t\\t\\t+------------------------+\")\r\n",
        "    print()\r\n",
        "    print()\r\n",
        "    print()\r\n",
        "    print(\"\\t\\t\\t     METRICS\")\r\n",
        "    print()\r\n",
        "    print()\r\n",
        "    print()\r\n",
        "    print(metrics.classification_report(y_test.argmax(axis=1), elm_result.argmax(axis=1)))\r\n",
        "    return con_mat\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVqDZJIIOg2r",
        "outputId": "7d0e5a63-416e-4174-c735-a0b2ee5ff56f"
      },
      "source": [
        "cnn = generate_cnn()        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 5, 64)             192       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4, 64)             8256      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 64)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 2, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               25800     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 34,650\n",
            "Trainable params: 34,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 211610 samples, validate on 26496 samples\n",
            "Epoch 1/100\n",
            "211610/211610 [==============================] - 12s 55us/sample - loss: 0.6683 - acc: 0.5932 - val_loss: 0.5759 - val_acc: 0.8964\n",
            "Epoch 2/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.5600 - acc: 0.6872 - val_loss: 0.5201 - val_acc: 0.9331\n",
            "Epoch 3/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.5077 - acc: 0.7181 - val_loss: 0.6783 - val_acc: 0.6213\n",
            "Epoch 4/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.4931 - acc: 0.7295 - val_loss: 0.4569 - val_acc: 0.9991\n",
            "Epoch 5/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.4843 - acc: 0.7405 - val_loss: 0.3348 - val_acc: 0.9992\n",
            "Epoch 6/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.4702 - acc: 0.7580 - val_loss: 0.5092 - val_acc: 0.8919\n",
            "Epoch 7/100\n",
            "211610/211610 [==============================] - 12s 55us/sample - loss: 0.4544 - acc: 0.7734 - val_loss: 0.3213 - val_acc: 0.9990\n",
            "Epoch 8/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.4328 - acc: 0.7895 - val_loss: 0.4844 - val_acc: 0.8791\n",
            "Epoch 9/100\n",
            "211610/211610 [==============================] - 12s 56us/sample - loss: 0.4094 - acc: 0.8034 - val_loss: 0.3957 - val_acc: 0.8777\n",
            "Epoch 10/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.3836 - acc: 0.8180 - val_loss: 0.4209 - val_acc: 0.8476\n",
            "Epoch 11/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.3615 - acc: 0.8306 - val_loss: 0.2751 - val_acc: 0.9663\n",
            "Epoch 12/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.3352 - acc: 0.8460 - val_loss: 1.4976 - val_acc: 0.3123\n",
            "Epoch 13/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.3157 - acc: 0.8561 - val_loss: 0.0258 - val_acc: 0.9992\n",
            "Epoch 14/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.2982 - acc: 0.8657 - val_loss: 0.2126 - val_acc: 0.9427\n",
            "Epoch 15/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.2780 - acc: 0.8775 - val_loss: 0.1863 - val_acc: 0.9583\n",
            "Epoch 16/100\n",
            "211610/211610 [==============================] - 11s 51us/sample - loss: 0.2621 - acc: 0.8868 - val_loss: 0.4508 - val_acc: 0.7552\n",
            "Epoch 17/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.2483 - acc: 0.8947 - val_loss: 0.2328 - val_acc: 0.8972\n",
            "Epoch 18/100\n",
            "211610/211610 [==============================] - 11s 51us/sample - loss: 0.2392 - acc: 0.8987 - val_loss: 0.1676 - val_acc: 0.9395\n",
            "Epoch 19/100\n",
            "211610/211610 [==============================] - 11s 51us/sample - loss: 0.2329 - acc: 0.9027 - val_loss: 0.5228 - val_acc: 0.6898\n",
            "Epoch 20/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.2183 - acc: 0.9100 - val_loss: 0.1757 - val_acc: 0.9273\n",
            "Epoch 21/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.2106 - acc: 0.9139 - val_loss: 0.0474 - val_acc: 0.9962\n",
            "Epoch 22/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.2034 - acc: 0.9166 - val_loss: 0.0741 - val_acc: 0.9898\n",
            "Epoch 23/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.2012 - acc: 0.9177 - val_loss: 0.0360 - val_acc: 0.9969\n",
            "Epoch 24/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1931 - acc: 0.9221 - val_loss: 0.0505 - val_acc: 0.9930\n",
            "Epoch 25/100\n",
            "211610/211610 [==============================] - 11s 51us/sample - loss: 0.1837 - acc: 0.9270 - val_loss: 0.0552 - val_acc: 0.9913\n",
            "Epoch 26/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1786 - acc: 0.9289 - val_loss: 0.0282 - val_acc: 0.9979\n",
            "Epoch 27/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1733 - acc: 0.9320 - val_loss: 1.5539 - val_acc: 0.4635\n",
            "Epoch 28/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1717 - acc: 0.9322 - val_loss: 0.0662 - val_acc: 0.9888\n",
            "Epoch 29/100\n",
            "211610/211610 [==============================] - 11s 51us/sample - loss: 0.1685 - acc: 0.9331 - val_loss: 0.0149 - val_acc: 0.9990\n",
            "Epoch 30/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1620 - acc: 0.9364 - val_loss: 0.1010 - val_acc: 0.9647\n",
            "Epoch 31/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1601 - acc: 0.9374 - val_loss: 0.0774 - val_acc: 0.9793\n",
            "Epoch 32/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1548 - acc: 0.9396 - val_loss: 0.1682 - val_acc: 0.9323\n",
            "Epoch 33/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1530 - acc: 0.9402 - val_loss: 0.4176 - val_acc: 0.8103\n",
            "Epoch 34/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1487 - acc: 0.9427 - val_loss: 0.0572 - val_acc: 0.9892\n",
            "Epoch 35/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1466 - acc: 0.9431 - val_loss: 0.0740 - val_acc: 0.9769\n",
            "Epoch 36/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1456 - acc: 0.9437 - val_loss: 0.1548 - val_acc: 0.9399\n",
            "Epoch 37/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1411 - acc: 0.9449 - val_loss: 0.0948 - val_acc: 0.9693\n",
            "Epoch 38/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1403 - acc: 0.9462 - val_loss: 0.1434 - val_acc: 0.9372\n",
            "Epoch 39/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1371 - acc: 0.9473 - val_loss: 0.2411 - val_acc: 0.8874\n",
            "Epoch 40/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1349 - acc: 0.9480 - val_loss: 0.1232 - val_acc: 0.9462\n",
            "Epoch 41/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1353 - acc: 0.9479 - val_loss: 0.0572 - val_acc: 0.9888\n",
            "Epoch 42/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1309 - acc: 0.9496 - val_loss: 0.1419 - val_acc: 0.9435\n",
            "Epoch 43/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1293 - acc: 0.9502 - val_loss: 0.0548 - val_acc: 0.9846\n",
            "Epoch 44/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1274 - acc: 0.9506 - val_loss: 0.2578 - val_acc: 0.8816\n",
            "Epoch 45/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1257 - acc: 0.9521 - val_loss: 0.1424 - val_acc: 0.9421\n",
            "Epoch 46/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1230 - acc: 0.9531 - val_loss: 0.3276 - val_acc: 0.8604\n",
            "Epoch 47/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1214 - acc: 0.9540 - val_loss: 0.2246 - val_acc: 0.9059\n",
            "Epoch 48/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1210 - acc: 0.9539 - val_loss: 0.1757 - val_acc: 0.9333\n",
            "Epoch 49/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1194 - acc: 0.9545 - val_loss: 0.0760 - val_acc: 0.9794\n",
            "Epoch 50/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1166 - acc: 0.9557 - val_loss: 0.0363 - val_acc: 0.9933\n",
            "Epoch 51/100\n",
            "211610/211610 [==============================] - 11s 51us/sample - loss: 0.1179 - acc: 0.9552 - val_loss: 0.0905 - val_acc: 0.9746\n",
            "Epoch 52/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1142 - acc: 0.9571 - val_loss: 0.1009 - val_acc: 0.9613\n",
            "Epoch 53/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1146 - acc: 0.9572 - val_loss: 0.0904 - val_acc: 0.9610\n",
            "Epoch 54/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1124 - acc: 0.9579 - val_loss: 0.5504 - val_acc: 0.7446\n",
            "Epoch 55/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1109 - acc: 0.9584 - val_loss: 0.0734 - val_acc: 0.9684\n",
            "Epoch 56/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1091 - acc: 0.9587 - val_loss: 0.1170 - val_acc: 0.9547\n",
            "Epoch 57/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1096 - acc: 0.9588 - val_loss: 0.1633 - val_acc: 0.9279\n",
            "Epoch 58/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1083 - acc: 0.9592 - val_loss: 0.0743 - val_acc: 0.9700\n",
            "Epoch 59/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1088 - acc: 0.9588 - val_loss: 0.1763 - val_acc: 0.9164\n",
            "Epoch 60/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1066 - acc: 0.9605 - val_loss: 0.0226 - val_acc: 0.9958\n",
            "Epoch 61/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1066 - acc: 0.9602 - val_loss: 0.0714 - val_acc: 0.9812\n",
            "Epoch 62/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1051 - acc: 0.9609 - val_loss: 0.0959 - val_acc: 0.9661\n",
            "Epoch 63/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1049 - acc: 0.9609 - val_loss: 0.3911 - val_acc: 0.8311\n",
            "Epoch 64/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.1032 - acc: 0.9613 - val_loss: 0.0872 - val_acc: 0.9685\n",
            "Epoch 65/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1034 - acc: 0.9614 - val_loss: 0.0317 - val_acc: 0.9936\n",
            "Epoch 66/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.1014 - acc: 0.9621 - val_loss: 0.0762 - val_acc: 0.9734\n",
            "Epoch 67/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.1001 - acc: 0.9627 - val_loss: 0.3615 - val_acc: 0.8505\n",
            "Epoch 68/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0973 - acc: 0.9637 - val_loss: 0.0334 - val_acc: 0.9928\n",
            "Epoch 69/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.0999 - acc: 0.9623 - val_loss: 0.0409 - val_acc: 0.9918\n",
            "Epoch 70/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.0973 - acc: 0.9635 - val_loss: 0.1042 - val_acc: 0.9571\n",
            "Epoch 71/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0948 - acc: 0.9650 - val_loss: 0.0918 - val_acc: 0.9672\n",
            "Epoch 72/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0962 - acc: 0.9642 - val_loss: 0.0294 - val_acc: 0.9945\n",
            "Epoch 73/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0943 - acc: 0.9648 - val_loss: 0.0648 - val_acc: 0.9766\n",
            "Epoch 74/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0959 - acc: 0.9645 - val_loss: 0.0876 - val_acc: 0.9626\n",
            "Epoch 75/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0954 - acc: 0.9645 - val_loss: 0.0354 - val_acc: 0.9925\n",
            "Epoch 76/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0936 - acc: 0.9658 - val_loss: 0.0296 - val_acc: 0.9947\n",
            "Epoch 77/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0938 - acc: 0.9653 - val_loss: 0.0796 - val_acc: 0.9751\n",
            "Epoch 78/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.0936 - acc: 0.9656 - val_loss: 0.0277 - val_acc: 0.9946\n",
            "Epoch 79/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0926 - acc: 0.9659 - val_loss: 0.3880 - val_acc: 0.8402\n",
            "Epoch 80/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0916 - acc: 0.9659 - val_loss: 0.0356 - val_acc: 0.9922\n",
            "Epoch 81/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0917 - acc: 0.9662 - val_loss: 0.0757 - val_acc: 0.9798\n",
            "Epoch 82/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0914 - acc: 0.9658 - val_loss: 0.2855 - val_acc: 0.8766\n",
            "Epoch 83/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0890 - acc: 0.9669 - val_loss: 0.0424 - val_acc: 0.9899\n",
            "Epoch 84/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0878 - acc: 0.9674 - val_loss: 0.1474 - val_acc: 0.9417\n",
            "Epoch 85/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0869 - acc: 0.9684 - val_loss: 0.0227 - val_acc: 0.9948\n",
            "Epoch 86/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0869 - acc: 0.9680 - val_loss: 0.4188 - val_acc: 0.8450\n",
            "Epoch 87/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0875 - acc: 0.9677 - val_loss: 0.0261 - val_acc: 0.9940\n",
            "Epoch 88/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0857 - acc: 0.9684 - val_loss: 0.2312 - val_acc: 0.9034\n",
            "Epoch 89/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0851 - acc: 0.9685 - val_loss: 0.0816 - val_acc: 0.9702\n",
            "Epoch 90/100\n",
            "211610/211610 [==============================] - 12s 55us/sample - loss: 0.0850 - acc: 0.9687 - val_loss: 0.0552 - val_acc: 0.9866\n",
            "Epoch 91/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0842 - acc: 0.9691 - val_loss: 0.1674 - val_acc: 0.9216\n",
            "Epoch 92/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0843 - acc: 0.9688 - val_loss: 0.0392 - val_acc: 0.9896\n",
            "Epoch 93/100\n",
            "211610/211610 [==============================] - 11s 54us/sample - loss: 0.0849 - acc: 0.9685 - val_loss: 0.0701 - val_acc: 0.9746\n",
            "Epoch 94/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0835 - acc: 0.9689 - val_loss: 0.1695 - val_acc: 0.9275\n",
            "Epoch 95/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0826 - acc: 0.9694 - val_loss: 0.0346 - val_acc: 0.9898\n",
            "Epoch 96/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.0824 - acc: 0.9692 - val_loss: 0.0501 - val_acc: 0.9865\n",
            "Epoch 97/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.0815 - acc: 0.9696 - val_loss: 0.0252 - val_acc: 0.9943\n",
            "Epoch 98/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0815 - acc: 0.9696 - val_loss: 0.3299 - val_acc: 0.8492\n",
            "Epoch 99/100\n",
            "211610/211610 [==============================] - 11s 52us/sample - loss: 0.0791 - acc: 0.9709 - val_loss: 0.4243 - val_acc: 0.8369\n",
            "Epoch 100/100\n",
            "211610/211610 [==============================] - 11s 53us/sample - loss: 0.0820 - acc: 0.9696 - val_loss: 0.7455 - val_acc: 0.7455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDYDltevRK7q"
      },
      "source": [
        "hidden_model, elm_input = hidden_layer_generate(cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lk2FkN_Sza6"
      },
      "source": [
        "elm = elm_model_generate(elm_input, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_eu-vjGTAGB",
        "outputId": "a2ab88d9-be3d-4da3-909f-c31ba481af97"
      },
      "source": [
        "cm=cnn_elm_evaluation(hidden_model, elm, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\t\t\t     CONFUSION MATRIX\n",
            "\t\t\t+------------------------+\n",
            "\t\t\t|\tTP  |\tFP\t |\n",
            "\t\t\t+------------------------+\n",
            "\t\t\t|\t 31 |\t 2 \t |\n",
            "\t\t\t+------------------------+\n",
            "\t\t\t|\t 43 |\t 26420 \t |\n",
            "\t\t\t+------------------------+\n",
            "\t\t\t|\tFN  |\tTN\t |\n",
            "\t\t\t+------------------------+\n",
            "\n",
            "\n",
            "\n",
            "\t\t\t     METRICS\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.94      0.58        33\n",
            "           1       1.00      1.00      1.00     26463\n",
            "\n",
            "    accuracy                           1.00     26496\n",
            "   macro avg       0.71      0.97      0.79     26496\n",
            "weighted avg       1.00      1.00      1.00     26496\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8o53UXJOKoF"
      },
      "source": [
        "CALCULATING METRICS MANUALLY "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_OrP4GVMubQ"
      },
      "source": [
        "#Accuracy = (TP+TN)/(TP+TN+FP+FN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw7O7e8jOJ9P",
        "outputId": "54e1882f-8463-4596-f955-209e3733be7a"
      },
      "source": [
        "print(\"Accuracy\",(cm[0][0]+cm[1][1])/cm.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.9983016304347826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFq13qExOdGe"
      },
      "source": [
        "#Precision = TP / (TP+FP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOXGYGeSOuHO",
        "outputId": "62260c75-5136-4e0c-cf4e-d332bce29bc5"
      },
      "source": [
        "prec=cm[0][0]/(cm[0][0]+cm[0][1])\n",
        "print(\"Precision\",cm[0][0]/(cm[0][0]+cm[0][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision 0.9393939393939394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOza5rqPtXE"
      },
      "source": [
        "#Recall = TP / (TP+FN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvlN17pePehU",
        "outputId": "cf2b2c09-f6ef-4e33-e3a9-b1757153bb6c"
      },
      "source": [
        "rec=cm[0][0]/(cm[0][0]+cm[1][0])\n",
        "print(\"Recall\",cm[0][0]/(cm[0][0]+cm[1][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall 0.4189189189189189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSNj2b1TQVQV"
      },
      "source": [
        "#F1-score = 2*[(Precision*Recall)/(Precision+Recall)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRe8X5pzP751",
        "outputId": "f9d94332-7cc7-4318-aaa0-14aa9b052fcd"
      },
      "source": [
        "print(\"F1 score\",2*(prec*rec/(prec+rec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score 0.5794392523364487\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}